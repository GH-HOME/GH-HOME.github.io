<!DOCTYPE html>
<html>
  <link href='//fonts.googleapis.com/css?family=Open+Sans:400italic,600italic,700italic,400,600,700' rel='stylesheet' type='text/css'>
  <head>
    <title>The Keras Tutorial - Introduction – Adrián Núñez-Marcos – PhD student at MORElab, University of Deusto</title>

        <meta charset="utf-8" />
    <meta content='text/html; charset=utf-8' http-equiv='Content-Type'>
    <meta http-equiv='X-UA-Compatible' content='IE=edge'>
    <meta name='viewport' content='width=device-width, initial-scale=1.0, maximum-scale=1.0'>

    
    <meta name="description" content="PhD student at MORElab, University of Deusto">
    <meta property="og:description" content="PhD student at MORElab, University of Deusto" />
    
    <meta name="author" content="Adrián Núñez-Marcos" />

    
    <meta property="og:title" content="The Keras Tutorial - Introduction" />
    <meta property="twitter:title" content="The Keras Tutorial - Introduction" />
    

    <!--[if lt IE 9]>
      <script src="http://html5shiv.googlecode.com/svn/trunk/html5.js"></script>
    <![endif]-->

    <link rel="stylesheet" type="text/css" href="/style.css" />
    <link rel="alternate" type="application/rss+xml" title="Adrián Núñez-Marcos - PhD student at MORElab, University of Deusto" href="/feed.xml" />

    <!-- Created with Jekyll Now - http://github.com/barryclark/jekyll-now -->
  </head>

  <body>
    <div class="wrapper-masthead">
      <div class="container">
        <header class="masthead clearfix">
          <!--<a href="/" class="site-avatar"><img src="https://morelab.deusto.es/media/persons/adrian-nunez-marcos.jpg" /></a>-->

          <div class="site-info">
            <h1 class="site-name"><a href="/">Adrián Núñez-Marcos</a></h1>
            <p class="site-description">PhD student at MORElab, University of Deusto</p>
          </div>

          <nav>
	    <a href="/">About me</a>
            <a href="/blog">Blog</a>
	    <a href="/news">News</a>
	    <a href="/research">Research</a>
	    <!--<a href="/publications-and-conferences">Publications and Conferences</a>-->
	    <a href="/miscellany">Misc</a>  
          </nav>
        </header>
      </div>
    </div>

    <div id="main" role="main" class="cuerpo container">
      <article class="post">
  <h1 style="font-size:180%;">The Keras Tutorial - Introduction</h1>
  <div class="date" style=" text-decoration: normal; font-size: 90%; margin-bottom: 1cm; ">
    14 Dec 2016
  </div>

  <div class="entry">
    <p><a href='https://keras.io/'>Keras</a> is a high-level neural networks library written in Python and built on top of <a href='http://deeplearning.net/software/theano/'>Theano</a> or <a href='https://www.tensorflow.org/'>Tensorflow</a>. That means you need one of them as a backend for Keras to work. I have been working with Neural Networks for a while, I have tried <a href='http://caffe.berkeleyvision.org/'>Caffe</a>, Tensorflow and <a href='http://torch.ch/'>Torch</a> and now I&#8217;m working with Keras. Its main advantage is the minimalism of the code as it allows the creation of big networks with a few lines of code. It allows multi-input and multi-ouput networks, convolutional and recurrent neural networks, embeddings, etc. I&#8217;m really comfortable working with it so I thought it would be nice to write some paragraphs to explain how it works and the tricks I found. I hope this tutorial is helpful for new users.</p>

<h3 id='index'>Index</h3>

<ul>
<li>Download and Install Keras</li>

<li>Backend</li>

<li>Our first Neural Network</li>

<li>The basic layers</li>
</ul>

<h2 id='download_and_install_keras'>Download and Install Keras</h2>

<p>Before we actually install Keras let&#8217;s make our life easier and install the pip program.</p>
<div>
  <pre><code class='ruby'>sudo apt-get install python-pip</code></pre>
</div>
<p>Now we can easily install the dependencies:</p>
<div>
  <pre><code class='ruby'>pip install numpy scipy scikit-learn pillow h5py</code></pre>
</div>
<p>Next we install Keras:</p>
<div>
  <pre><code class='ruby'>pip install keras</code></pre>
</div>
<p>You can check the version of Keras you are using by typing the following command in the terminal:</p>
<div>
  <pre><code class='ruby'>python -c &quot;import keras; print keras.__version__&quot;</code></pre>
</div>
<p>Moreover, you can upgrade Keras with the following command:</p>
<div>
  <pre><code class='ruby'>sudo pip install --upgrade keras</code></pre>
</div>
<h2 id='backend'>Backend</h2>

<p>As I mentioned earlier, Keras works on top of Tensorflow (by default) or Theano. I tend to use Theano as my backend. To specify which <a href='https://keras.io/backend/'>backend</a> we want to use we have to edit the keras.json file:</p>
<div>
  <pre><code class='ruby'>nano ~/.keras/keras.json</code></pre>
</div>
<p>Example of the content of my keras.json file using Theano:</p>
<div>
  <pre><code class='ruby'>{
    &quot;image_dim_ordering&quot;: &quot;th&quot;, 
    &quot;epsilon&quot;: 1e-07, 
    &quot;floatx&quot;: &quot;float32&quot;, 
    &quot;backend&quot;: &quot;theano&quot;
}</code></pre>
</div>
<p>In the &#8216;backend&#8217; variable we can specify &#8216;theano&#8217; or &#8216;tensorflow&#8217;. The &#8216;image_dim_ordering&#8217; (&#8216;th&#8217; for theano and &#8216;tf&#8217; for tensorflow) is used to specify the arrangement of the dimensions in images, i.e. in Theano we use the order (channels, width, height) whereas in Tensorflow the order is (width, height, channels). In the case of theano, you have to create a file &#8216;~/.theanorc&#8217;:</p>
<div>
  <pre><code class='ruby'>touch ~/.theanorc</code></pre>
</div>
<p>And include the following:</p>
<div>
  <pre><code class='ruby'>[global]
floatX = float32
device = gpu
optimizer = fast_run
 
[lib]
cnmem = 0.9
 
[nvcc]
fastmath = True
 
[blas]
ldflags = -llapack -lblas</code></pre>
</div>
<p>If you want to use the CPU change &#8216;gpu0&#8217; to &#8216;cpu&#8217;. With this final steps we should have keras ready to work with Theano.</p>

<h2 id='our_first_neural_network'>Our first Neural Network</h2>

<p>First I will say that Keras has two different structures to create Neural Networks: the Sequential Model and the Functional API. We will work with the second one through the tutorial as it allows more freedom. If you have heard about the Graph Model I have to say that it was removed (therefore it&#8217;s now deprecated) in the version 1.0 (<a href='https://github.com/fchollet/keras/issues/2802#issuecomment-221314411'>link</a>).</p>

<p>So let&#8217;s start coding! Our first neural network is going to have a single input and a final dense layer (which will be the output). The example code can also be shown in the <a href='https://keras.io/models/model/'>Keras Models section</a> but we will go through each of the lines to understand better what we are doing.</p>
<div>
  <pre><code class='python'>from keras.models import Model
from keras.layers import Input, Dense

a = Input(shape=(32,))
b = Dense(32)(a)
model = Model(input=a, output=b)</code></pre>
</div>
<p>The first two lines are the imports. No need for explanation, we need to import all the layers, optimizers, functions for the initilisation of layers, etc. we want to use.</p>

<p>The Functional API forces you to include an input layer. Here you have to specify the shape of your input (without the batch size). In this example we only have a 1D input of 32 values. The comma after the value 32 is also mandatory in some cases to avoid errors. Your input layer is stored in the variable &#8216;a&#8217;, so you can use this variable as input to other variables to create links (this allows the network to branch out easily).</p>

<p>Now we include a Dense layer by calling the function and providing the number of neurons for that layer (in this case 32). The next step is to stack the output layer or dense layer on top of the input layer, i.e., we have to connect them. In this type of model we do this by providing the variable of the last layer at the end of the new layer (check the &#8216;a&#8217; between parenthesis after the Dense layer).</p>

<p>Finally, we have to instantiate the Model or create a container for it. We can do this with the Model function, providing the input and output. In this case providing the variables of the input and output layers. We can also provide a Python list for multi-input and output.</p>
<div>
  <pre><code class='python'>a = Input(shape=(32,))
b = Input(shape=(32,))
...
z = merge([a,b], mode='concat', concat_axis = -1)
...
c = Dense(32)(z)
model = Model(input=[a, b], output=c)</code></pre>
</div>
<p>This is an example of a multi-input neural network, in this case a and b. At some point in the code we have to fuse both of them into one stream, which we cal z. Finally, we will output c.</p>

<p>Anyway, now that the model is created we have to configure it. To do so we have to call the function &#8216;compile&#8217; of the model:</p>
<div>
  <pre><code class='python'>compile(self, optimizer, loss, metrics=None, loss_weights=None, sample_weight_mode=None)</code></pre>
</div>
<p>We have to pass an optimizer and a loss function at least. You can check the <a href='https://keras.io/optimizers/'>optimizers section</a> and the <a href='https://keras.io/objectives/'>loss, objective or cost function section</a> of the webpage of Keras for information about the available functions.</p>

<p>Once we have the model ready is time to actually train it. This can be done in various ways, we explain the simple one: using the &#8216;fit&#8217; function of the model:</p>
<div>
  <pre><code class='python'>fit(self, x, y, batch_size=32, nb_epoch=10, verbose=1, callbacks=None, validation_split=0.0, validation_data=None, shuffle=True, class_weight=None, sample_weight=None, initial_epoch=0)</code></pre>
</div>
<p>This function expects at least the input data X (which can be a list if it&#8217;s a muti-input network), the true labels Y (again, it can be an array). You can also specify the batch size, number of epochs, the validation split (between 0 and 1, percentage of the training data that will be used for validation) or validation data (a pair of validation data and true labels), etc.</p>

<p>Finally, you can evaluate your trained model with the &#8216;evaluate&#8217; function:</p>
<div>
  <pre><code class='python'>evaluate(self, x, y, batch_size=32, verbose=1, sample_weight=None)</code></pre>
</div>
<p>You have to provide it with test data or data that has not been used during training. The accuracy provided by this process measures the real quality of your model.</p>

<p>And this concludes our first neural network tutorial! I will write now about some basic stuff about Neural Networks: layers, initialisation, etc. I hope it&#8217;s clear enough. For any question or suggestions please use the comments section below.</p>

<h2 id='the_basic_layers'>The basic layers</h2>

<ul>
<li>Input layer: The input layer specifies the shape of the input. This replaces the old and mandatory parameter &#8216;input_shape&#8217; that had to be added to the first layer of the network. The parameter shape expects the shape without the batch size. The final comma is also necessary.</li>
</ul>
<div>
  <pre><code class='python'>keras.layers.Input(shape, batch_shape, dtype, name)</code></pre>
</div>
<ul>
<li>Dense layer: The Dense layer or Fully-connected layer is the most basic Neural Network layer composed by a number of neurons specified by the parameter output_dim (greater than 0).</li>
</ul>
<div>
  <pre><code class='python'>keras.layers.core.Dense(output_dim, init='glorot_uniform', activation=None, weights=None, W_regularizer=None, b_regularizer=None, activity_regularizer=None, W_constraint=None, b_constraint=None, bias=True, input_dim=None)</code></pre>
</div>
<ul>
<li>Activation (layer): Not really a layer. It applies an activation function (which must be included as a parameter) to the previous layer&#8217;s neurons. Its use can be avoided by specifying the parameter &#8216;activation&#8217; in the previous layer. Anyway, it comes in handy when you want to apply a function between the linear and non-linear operation. You can check in <a href='https://github.com/fchollet/keras/blob/master/keras/activations.py'>the code</a> the activation functions included in Keras. These are available: softmax, elu, softplus, softsign, relu, tanh, sigmoid, hard_sigmoid and linear. Note that the linear function is the identity function as, by default, the previous layer applies the linear activation function by default.</li>
</ul>
<div>
  <pre><code class='python'>keras.layers.core.Activation(activation)</code></pre>
</div>
<ul>
<li>Flatten layer: Not really a layer. It&#8217;s a reshape operation to transform a nD array into a 2D array with shape (batch size, features). This operation is usually followed by a Dense layer.</li>
</ul>
<div>
  <pre><code class='python'>keras.layers.core.Flatten()</code></pre>
</div>
<ul>
<li>Merge layer: The merge layer fuses various tensors into a single one. This is useful to create multiple streams (each one with its own input) and then merge them. The first argument is a list of the tensors, the mode specifies how to merge them (concatenation, sum&#8230;) and the concat_axis tells the layer which axis to pick to make the concatenation (-1 by default).</li>
</ul>
<div>
  <pre><code class='python'>keras.layers.merge(layers, mode, concat_axis)</code></pre>
</div>
<ul>
<li>Dropout layer: Not really a layer. From the paper <a href='http://www.jmlr.org/papers/volume15/srivastava14a/srivastava14a.pdf'>&#8216;Dropout: A Simple Way to Prevent Neural Networks from Overfitting, 2014&#8217;</a> The dropout operation is a way of preventing overfitting and hence improving the generalisation. During training time, it drops with a probability p (given as a parameter) the previous layer&#8217;s neurons, i.e., their activations become 0.</li>
</ul>
<div>
  <pre><code class='python'>keras.layers.core.Dropout(p)</code></pre>
</div>
<h2 id='initialisation'>Initialisation</h2>

<p>The initialisation of a neural network (non-convex function) is important as we try to make it converge. We should initialise all neurons with a specific method. The <a href='https://keras.io/initializations/'>initialisation section</a> in the webpage of Keras provides a list of all the initialisation options implemented in Keras. First, you have to import them:</p>
<div>
  <pre><code class='python'>from keras.initializations import uniform</code></pre>
</div>
<p>An example of importing the uniform initialisation function. These functions are given as the value of the parameter &#8216;init&#8217; that some Keras layers have, e.g., the Dense layer.</p>
  </div>

  
<div id="disqus_thread"></div>
<script>

/**
*  RECOMMENDED CONFIGURATION VARIABLES: EDIT AND UNCOMMENT THE SECTION BELOW TO INSERT DYNAMIC VALUES FROM YOUR PLATFORM OR CMS.
*  LEARN WHY DEFINING THESE VARIABLES IS IMPORTANT: https://disqus.com/admin/universalcode/#configuration-variables
*/

var disqus_config = function () {
this.page.url = 'https://adriannunez.github.io/';  // Replace PAGE_URL with your page's canonical URL variable
this.page.identifier = ''; // Replace PAGE_IDENTIFIER with your page's unique identifier variable
};

(function() { // DON'T EDIT BELOW THIS LINE
var d = document, s = d.createElement('script');
s.src = '//https-adriannunez-github-io.disqus.com/embed.js';
s.setAttribute('data-timestamp', +new Date());
(d.head || d.body).appendChild(s);
})();
</script>
<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>


</article>

    </div>

    <div class="wrapper-footer">
      <div class="container">
        <footer class="footer">
          
<a href="mailto:adrian.nunez@deusto.es"><i class="svg-icon email"></i></a>


<a href="https://github.com/AdrianNunez"><i class="svg-icon github"></i></a>

<a href="https://www.linkedin.com/in/anunezmarcos"><i class="svg-icon linkedin"></i></a>


<a href="https://www.twitter.com/anunezmarcos"><i class="svg-icon twitter"></i></a>



        </footer>
      </div>
    </div>

    
	<!-- Google Analytics -->
	<script>
		(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
		(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
		m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
		})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

		ga('create', 'UA-91629881-1', 'auto');
		ga('send', 'pageview', {
		  'page': '/the-keras-tutorial-introduction/',
		  'title': 'The Keras Tutorial - Introduction'
		});
	</script>
	<!-- End Google Analytics -->


  </body>
</html>
