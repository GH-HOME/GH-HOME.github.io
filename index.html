

<html>
    <head>
        <title>Heng's Homepage </title>
	</head>
    <body style="font-size: 24px;">
		<table border=0 width=1200px align=center>
			<tr>
      			<td valign="top">
                <img img width=180 src="portrait/logo_bupt.png">
        		<br>
        <table>
            <tr>
                <td>
				<font face="helvetica, ariel, 'sans serif'" size="6"> 
					<strong>Heng Guo  郭亨</strong><br>
                <br>
				</font>
                

				<font face="helvetica, ariel, 'sans serif'" size="4"> 
					Specially Appointed Researcher (特聘研究员)
				<br>	
				<br>
					PRIS Lab
				<br>
					School of Artificial Intelligence
				<br>
                    Beijing University of Posts and Telecommunications
				<br>
				<br>
					Email: guoheng [at] bupt.edu.cn
				<br>
					<a href="https://github.com/GH-HOME">[GITHUB] </a>  
					<a href="CV/CV_en.pdf">    [CV] </a> 
					<a href="https://scholar.google.com/citations?hl=zh-CN&view_op=list_works&gmla=AJsN-F5heF8L-qMhjxAo6o2tbLndAtQ9I1oj0TlCmTe2EP0C8RxEg9-inIZhyzvQ_WCVHzWUsymOWie8WAseZZT_O2RY1NgpYtYNp24rNMEyRgyL93YVpts&user=HKu6gF4AAAAJ">    [Google Scholar] </a> 
				<br>
                <p style="margin-top: 8px; margin-bottom: 8px;"></p>
                <font color="red"><highlight>★ 
                    Looking for MPhil/PhD students (2025 Fall) and RAs to work with me at BUPT.
                </highlight></font>
                </font>
              </td>
                <td width = "45%" align="right">
                  <img height=300 src="portrait/portrait.jpg" border="2">
              	</td>
            </tr>
        </table>
        <p>
        <hr size="1" align="left" noshade>
        <p>

        <font face="helvetica, ariel, 'sans serif'">
        <h2>About Me</h2>
        I received my Ph.D. (Oct. 2018 - Mar. 2022) from Osaka University under the supervision of <a href="http://www-infobiz.ist.osaka-u.ac.jp/en/member/matsushita/">Prof. Yasuyuki Matsushita</a> and Prof. <a href="https://camera.pku.edu.cn/People.htm">Boxin Shi</a>. Previously I obtained my Master and Bachelor degree in 2018 and 2015, both from University of Electronic Science and Technology of China (<strong><a href="http://www.uestc.edu.cn/">UESTC</a></strong>), under the supervision of Prof. Bing Zeng and <a href="http://www.liushuaicheng.org">Prof. Shuaicheng Liu</a>.
        My research interest includes computational photograpy and computer vision.

    	<h2>News</h2>
            <li><strong>[2024/02]</strong> Two papers are accepted by CVPR 2024! </li>
            <li><strong>[2023/07]</strong> Two papers are accepted by ICCV 2023! </li>
            <li><strong>[2023/07]</strong> One paper is accepted by IC-NIDC 2023! </li>
            <li><strong>[2023/07]</strong> Two papers are accepted by ICCP 2023! </li>
            <li><strong>[2023/05]</strong> One paper is accepted by IJCAI 2023! </li>
			<li><strong>[2022/03]</strong> Obtain my Ph.D degree! </li>


        <h2>Publications </h2>
        <font face="helvetica, ariel, 'sans serif'">
            <table border="0" cellpadding="20" cellspacing="3" >


                <tr>
                    <td style="padding:20px;width:25%;vertical-align:middle">
                        <img width="320" src="project/CVPR24/guo/DiLiGenRT.jpg" border="3">
                    </td>
                    <td style="padding:20px;width:75%;vertical-align:middle">
                        <strong>NeRSP: Neural 3D Reconstruction for Reflective Objects with Sparse Polarized Images</strong> <br>
                        <strong>Heng Guo</strong>,
                        Jieji Ren, 
                        Feishi Wang, 
                        Mingjun Ren, 
                        Boxin Shi, 
                        <a href="http://www-infobiz.ist.osaka-u.ac.jp/en/member/matsushita/">Yasuyuki Matsushita</a>
                        <br>
                        In <em>IEEE Conference on Computer Vision and Pattern Recognition  </em> (<strong>CVPR 2024</strong>). 
                        <br>
                        [<a href="https://openaccess.thecvf.com/content/CVPR2024/papers/Guo_DiLiGenRT_A_Photometric_Stereo_Dataset_with_Quantified_Roughness_and_Translucency_CVPR_2024_paper.pdf">Paper</a>] [<a href="https://photometricstereo.github.io/diligentrt.html">Project page</a>]
                    </td>
                </tr>

                <tr>
                    <td style="padding:20px;width:25%;vertical-align:middle">
                        <img width="320" src="project/CVPR24/han/NeRSP.jpg" border="3">
                    </td>
                    <td style="padding:20px;width:75%;vertical-align:middle">
                        <strong>NeRSP: Neural 3D Reconstruction for Reflective Objects with Sparse Polarized Images</strong> <br>
                        <a href="https://yu-fei-han.github.io/homepage/">Yufei Han</a>,
                        <strong>Heng Guo*</strong>,
                        Koki Fukai, 
                        <a href="https://sites.google.com/view/hiroaki-santo/">Hiroaki Santo</a>, 
                        <a href="https://camera.pku.edu.cn/">Boxin Shi</a>, 
                        <a href="http://cvl.ist.osaka-u.ac.jp/user/okura/">Fumio Okura</a>, 
                        <a href="https://zhanyuma.cn">Zhanyu Ma</a>, 
                        <a href="https://sdmda.bupt.edu.cn/info/1061/1060.htm">Yunpeng Jia</a>
                        <br>
                        In <em>IEEE Conference on Computer Vision and Pattern Recognition  </em> (<strong>CVPR 2024</strong>). 
                        <br>
                        [<a href="https://arxiv.org/abs/2406.07111">Paper</a>] [<a href="https://yu-fei-han.github.io/NeRSP-project/">Project page</a>][<a href="https://github.com/PRIS-CV/NeRSP">Code</a>]
                    </td>
                </tr>


                <tr>
                    <td>
                        <img width=320 src="project/ICCV23/chen/teaser-min.png" loop=infinite border="3">
                    </td>
                    <td align="left"><strong>ReLeaPS : Reinforcement Learning-based Illumination Planning for Generalized Photometric Stereo </strong> <br>
                        Jun Hoong Chan, Bohan Yu, <strong>Heng Guo</strong>, Jieji Ren, Zongqing Lu, Boxin Shi<br>
                        In <em>International Conference on Computer Vision   </em> (<strong>ICCV 2023</strong>). <br>
						[<a href="https://openaccess.thecvf.com/content/ICCV2023/papers/Chan_ReLeaPS__Reinforcement_Learning-based_Illumination_Planning_for_Generalized_Photometric_Stereo_ICCV_2023_paper.pdf">Paper</a>] [<a href="https://jhchan0805.github.io/ReLeaPS/">Project page</a>]
                    </td>
                </tr>


                <tr>
                    <td>
                        <img width=320 src="project/ICCV23/wang/teaser-min.png" loop=infinite border="3">
                    </td>
                    <td align="left"><strong>DiLiGenT-Pi: Photometric Stereo for Planar Surfaces with Rich Details – Benchmark Dataset and Beyond </strong> <br>
                        Feishi Wang, Jieji Ren, <strong>Heng Guo</strong>, Mingjun Ren, Boxin Shi<br>
                        In <em>International Conference on Computer Vision   </em> (<strong>ICCV 2023</strong>). <br>
						[<a href="https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_DiLiGenT-Pi_Photometric_Stereo_for_Planar_Surfaces_with_Rich_Details_-_ICCV_2023_paper.pdf">Paper</a>] [<a href="https://photometricstereo.github.io/diligentpi.html">Project page</a>]
                    </td>
                </tr>


                <tr>
                    <td>
                        <img width=320 src="project/ICCP23/Li/teaser-min.png" loop=infinite border="3">
                    </td>
                    <td align="left"><strong>Learning to Synthesize Photorealistic Dual-pixel Images from RGBD frames </strong> <br>
                      Feiran Li, <strong>Heng Guo</strong>, Hiroaki Santo, Fumio Okura, <a href="http://www-infobiz.ist.osaka-u.ac.jp/en/member/matsushita/">Yasuyuki Matsushita</a>. <br>
						In <em>International Conference on Computational Photography   </em> (<strong>ICCP 2023</strong>). <br>
						[<a href="project/ICCP23/Li/paper.pdf">Paper</a>] [<a href="https://github.com/SILI1994/Neural-Dual-Pixel-Simulator">Code and dataset</a>]
                    </td>
                </tr>


                <tr>
                    <td>
                        <img width=320 src="project/ICCP23/Makabe/teaser-min.png" loop=infinite border="3">
                    </td>
                    <td align="left"><strong>Near-light Photometric Stereo with Symmetric Lights </strong> <br>
                      Lilika Makabe, <strong>Heng Guo</strong>, Hiroaki Santo, Fumio Okura, <a href="http://www-infobiz.ist.osaka-u.ac.jp/en/member/matsushita/">Yasuyuki Matsushita</a>. <br>
						In <em>International Conference on Computational Photography   </em> (<strong>ICCP 2023</strong>). <br>
						[<a href="project/ICCP23/Makabe/paper.pdf">Paper</a>][<a href="project/ICCP23/Makabe/supp.pdf">Supp</a>]
                    </td>
                </tr>

              <tr>
                    <td>
                        <img width=320 src="project/ICNIDC/teaser-min.png" loop=infinite border="3">
                    </td>
                    <td align="left"><strong>Neural BRDF Plugin for Unsupervised Photometric Stereo </strong> <br>
                      <strong>Heng Guo</strong>, <a href="http://alumni.media.mit.edu/~shiboxin/">Boxin Shi</a>, <a href="http://www-infobiz.ist.osaka-u.ac.jp/en/member/matsushita/">Yasuyuki Matsushita</a>. <br>
                    <br>
						In <em>IEEE International Conference on Network Intelligence and Digital Content   </em> (<strong>IC-NIDC 2023</strong>). <br>
						[<a href="project/ICNIDC/paper.pdf">Paper</a>][<a href="project/ICNIDC/award.png">Award</a>]
                    </td>
                </tr>

                <tr>
                    <td>
                        <img width=320 src="project/IJCAI23/teaser-min.png" loop=infinite border="3">
                    </td>
                    <td align="left"><strong>Non-Lambertian Multispectral Photometric Stereo via Spectral Reflectance Decomposition </strong> <br>
                      Jipeng Lv, <strong>Heng Guo</strong>, Guanying Chen, Jinxiu Liang, <a href="http://alumni.media.mit.edu/~shiboxin/">Boxin Shi</a>.
                    <br>
						In <em>International Joint Conferences on Artificial Intelligence   </em> (<strong>IJCAI 2023</strong>). <br>
						[<a href="https://www.ijcai.org/proceedings/2023/0139.pdf">Paper</a>] [<a href="https://github.com/Github-Tree-0/NeuralMPS">Code and dataset</a>]
                    </td>
                </tr>


                <tr>
                    <td>
                        <img width=320 src="project/TPAMI22/Thumb.gif" loop=infinite border="3">
                    </td>
                    <td align="left"><strong>Edge-preserving Near-light Photometric Stereo with Neural Surfaces </strong> <br>
                      <strong>Heng Guo</strong>, Hiroaki Santo, <a href="http://alumni.media.mit.edu/~shiboxin/">Boxin Shi</a>, <a href="http://www-infobiz.ist.osaka-u.ac.jp/en/member/matsushita/">Yasuyuki Matsushita</a>. <br>
                        Pre-print
						[<a href="https://arxiv.org/abs/2207.04622">Paper</a>]
                    </td>
                </tr>


                <tr>
                    <td>
                        <img width=320 src="project/IJCV22/teaser.png" loop=infinite border="3">
                    </td>
                    <td align="left"><strong>Multispectral Photometric Stereo for Spatially-Varying Spectral Reflectances </strong> <br>
                      <strong>Heng Guo</strong>, Fumio Okura, <a href="http://alumni.media.mit.edu/~shiboxin/">Boxin Shi</a>, Takuya Funatomi, Yasuhiro Mukaigawa, <a href="http://www-infobiz.ist.osaka-u.ac.jp/en/member/matsushita/">Yasuyuki Matsushita</a>. <br>
                        In <em>International Journal of Computer Vision  </em> (<strong>IJCV 2022</strong>). <br>
						[<a href="project/IJCV22/paper.pdf">Paper</a>] [<a href="https://youtu.be/hUsMz5dCHnE">Video</a>] [<a href="https://drive.google.com/file/d/1OLY655RT7Eroyr6UZcg97DkJrRRCURHZ/view?usp=sharing">MPS data</a>]
                        
                    </td>
                </tr>

                <tr>
                    <td>
                        <img width=320 src="project/TPAMI21/teaser2.png" loop=infinite border="3">
                    </td>
                    <td align="left"><strong> Patch-based Uncalibrated Photometric Stereo under Natural Illumination</strong> <br>
                      <strong>Heng Guo</strong>, Zhipeng Mo, <a href="http://alumni.media.mit.edu/~shiboxin/">Boxin Shi</a>, Feng Lu, Sai-Kit Yeung, Ping Tan, <a href="http://www-infobiz.ist.osaka-u.ac.jp/en/member/matsushita/">Yasuyuki Matsushita</a>. <br>
                        In <em>IEEE Transactions on Pattern Analysis and Machine Intelligence  </em> (<strong>TPAMI 2021</strong>). <br>
						[<a href="project/TPAMI21/paper.pdf">Paper</a>]
                    </td>
                </tr>

				<tr>
                    <td>
                        <img width=320 src="project/CVPR21/Thumbnail.gif" loop=infinite border="3">
                    </td>
                    <td align="left"><strong>Multispectral Photometric Stereo for Spatially-Varying Spectral Reflectances: A well posed probelm? </strong> <br>
                      <strong>Heng Guo</strong>, Fumio Okura, <a href="http://alumni.media.mit.edu/~shiboxin/">Boxin Shi</a>, Takuya Funatomi, Yasuhiro Mukaigawa, <a href="http://www-infobiz.ist.osaka-u.ac.jp/en/member/matsushita/">Yasuyuki Matsushita</a>. <br>
                        In <em>IEEE Conference on Computer Vision and Pattern Recognition  </em> (<strong>CVPR 2021</strong>). <br>
						[<a href="https://openaccess.thecvf.com/content/CVPR2021/papers/Guo_Multispectral_Photometric_Stereo_for_Spatially-Varying_Spectral_Reflectances_A_Well_Posed_CVPR_2021_paper.pdf">Paper</a>]
                        [<a href="https://youtu.be/jot_BPFUJko">Video</a>]
                        [<a href="https://docs.google.com/presentation/d/1RouZBUe5RDMA0XxLvcoLZepQxULkppMd/edit?usp=sharing&ouid=117990209997485642808&rtpof=true&sd=true">Slide</a>]
                        [<a href="project/CVPR21/poster.pdf">Poster</a>]
                    </td>
                </tr>
				
                <tr>
                    <td>
                        <img width=320 src="project/MIRU20/MIRU2020-min.png" border="3">
                    </td>
                    <td align="left"><strong>Self-calibrating Near-light Photometric Stereo under Anisotropic Light Emission </strong> <br>
                      <strong>Heng Guo</strong>, <a href="http://alumni.media.mit.edu/~shiboxin/">Boxin Shi</a>, Michael Waechter, <a href="http://www-infobiz.ist.osaka-u.ac.jp/en/member/matsushita/">Yasuyuki Matsushita</a>. <br>
                        In <em>Meeting on Image Recognition and Understanding </em> (<strong>MIRU 2020</strong>). (Best Student Paper) <br>
                        [<a href="project/MIRU20/MIRU2020.pdf">Paper</a>] [<a href="project/MIRU20/award_low.pdf">Award</a>]
                    </td>
                </tr>


                <tr>
                    <td>
                        <img width=320 src="project/TCI18/TCI2018.PNG" border="3">
                  	</td>
                    <td align="left"><strong>View-Consistent MeshFlow for Stereoscopic Video Stabilization </strong> <br>
                      <strong>Heng Guo</strong>, <a href="http://www.liushuaicheng.org/">Shuaicheng Liu</a>, Shuyuan Zhu, Heng Tao Shen, Bing Zeng. <br>
                        In <em>IEEE Transactions on Computational Imaging </em> (<strong>TCI 2018</strong>). <br>
                        [<a href="paper/StereoStabilization-TCI-2018.pdf">Paper</a>]
						[<a href="https://youtu.be/ElmR6cOZF-8">Video</a>]
					</td>
                </tr>


                <tr>
                    <td>
                        <img width=320 src="project/ICIP16/ICIP2016.jpg" border="3">
                    </td>
					<td><strong>Joint Bundled Camera Paths for StereoScopic Video Stabilization </strong> <br>
                        <strong>Heng Guo</strong>, <a href="http://www.liushuaicheng.org/">Shuaicheng Liu</a>, Shuyuan Zhu, Bing Zeng<br>
                        In <em>International Conference on Image Processing </em> (<strong>ICIP 2016</strong>) (Oral)<br>
                        [<a href="http://www.liushuaicheng.org/ICIP2016/stabilization/StereoStb.pdf">Paper</a>]   [<a href="project/ICIP16/index.html">Website</a>]<br>
					</td>
                </tr>

                <tr>
                    <td>
                        <img width=320 src="project/TIP16/TIP2016.jpg" border="3">
                  	</td>
                    <td><strong>Joint Video Stitching and Stabilization from Moving Cameras </strong> <br>
                      <strong>Heng Guo</strong>, <a href="http://www.liushuaicheng.org/">Shuaicheng Liu</a>, Tong He, Shuyuan Zhu, Bing Zeng, Moncef Gabbouj.<br>
                    In <em>IEEE Transactions on Image Processing</em> (<strong>TIP 2016</strong>) <br>
                    [<a href="http://www.liushuaicheng.org/TIP/VideoStitching2016/tip16.pdf">Paper</a>]    [<a href="http://www.liushuaicheng.org/TIP/VideoStitching2016/index.html">Website</a>]</td>
                </tr>

            </table>
        </font>
			
<p>
	<hr size="1" align="left" noshade>
<p>
	
<table border=0 width=250 align=center>
	<tbody>
		<tr>
			<td align="center" width="250px">
				<script type="text/javascript" id="clustrmaps" src="//clustrmaps.com/map_v2.js?d=HpCmnzeCJi8rrXVVBPiyRQw_54PhDvHIQRWoVNmbR4g&cl=ffffff&w=a"></script>
			</td>
		<tr>
	</tbody>
</table>


</body>
</html>
